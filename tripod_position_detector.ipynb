{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUIqoh5F_fil",
        "outputId": "57c15391-95ed-46e0-9b23-98ca56c75810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.12/dist-packages (0.10.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Kkyhbfex93wA"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from math import atan2, degrees\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "# Initialize MediaPipe\n",
        "mp_pose = mp.solutions.pose\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "\n",
        "def angle_2d(a, b):\n",
        "    \"\"\"Returns angle between horizontal and line a->b in degrees.\"\"\"\n",
        "    return degrees(atan2(b[1] - a[1], b[0] - a[0]))\n",
        "\n",
        "\n",
        "def distance(a, b):\n",
        "    \"\"\"Euclidean distance between 2D points.\"\"\"\n",
        "    return np.hypot(a[0] - b[0], a[1] - b[1])\n",
        "\n",
        "\n",
        "def evaluate_tripod_strict(landmarks, image_shape):\n",
        "    \"\"\"Compute if person is in tripod position using stricter geometric rules.\"\"\"\n",
        "    h, w, _ = image_shape\n",
        "\n",
        "    def get_landmark(idx):\n",
        "        lm = landmarks[idx]\n",
        "        return np.array([lm.x * w, lm.y * h])\n",
        "\n",
        "    # Points clés\n",
        "    shoulder_r = get_landmark(mp_pose.PoseLandmark.RIGHT_SHOULDER.value)\n",
        "    shoulder_l = get_landmark(mp_pose.PoseLandmark.LEFT_SHOULDER.value)\n",
        "    hip_r = get_landmark(mp_pose.PoseLandmark.RIGHT_HIP.value)\n",
        "    hip_l = get_landmark(mp_pose.PoseLandmark.LEFT_HIP.value)\n",
        "    knee_r = get_landmark(mp_pose.PoseLandmark.RIGHT_KNEE.value)\n",
        "    knee_l = get_landmark(mp_pose.PoseLandmark.LEFT_KNEE.value)\n",
        "    wrist_r = get_landmark(mp_pose.PoseLandmark.RIGHT_WRIST.value)\n",
        "    wrist_l = get_landmark(mp_pose.PoseLandmark.LEFT_WRIST.value)\n",
        "\n",
        "    # Centres\n",
        "    shoulder = (shoulder_r + shoulder_l) / 2\n",
        "    hip = (hip_r + hip_l) / 2\n",
        "    knee_mid = (knee_r + knee_l) / 2\n",
        "\n",
        "    # Distance de référence : largeur des épaules\n",
        "    ref_dist = distance(shoulder_r, shoulder_l)\n",
        "\n",
        "    # --- 1️⃣ Vérifier que le torse est fortement penché en avant ---\n",
        "    torso_angle = abs(angle_2d(hip, shoulder))  # 90 = vertical\n",
        "    leaning_forward = (35 <= torso_angle <= 60)\n",
        "\n",
        "    # --- 2️⃣ Vérifier que la personne est clairement assise ---\n",
        "    hip_to_knee_ratio = (hip[1] - knee_mid[1]) / ref_dist\n",
        "    # Hanches à hauteur des genoux (valeurs plus grandes = personne debout)\n",
        "    sitting_like = (-0.5 < hip_to_knee_ratio < 0.2)\n",
        "\n",
        "    # --- 3️⃣ Vérifier que les mains sont très proches des genoux ---\n",
        "    dist_r = distance(wrist_r, knee_r) / ref_dist\n",
        "    dist_l = distance(wrist_l, knee_l) / ref_dist\n",
        "    hands_near_knees = (dist_r < 0.6 and dist_l < 0.6)\n",
        "\n",
        "    # --- 4️⃣ Vérifier que les mains sont en avant du corps (pas derrière) ---\n",
        "    hands_forward = ((wrist_r[1] > shoulder_r[1]) and (wrist_l[1] > shoulder_l[1]))\n",
        "\n",
        "    # --- 5️⃣ Vérifier la symétrie gauche/droite ---\n",
        "    symmetry = abs((wrist_r[1] - wrist_l[1])) < (0.3 * ref_dist)\n",
        "\n",
        "    # --- 6️⃣ Combiner avec pondérations plus strictes ---\n",
        "    score = (0.35 * leaning_forward +\n",
        "             0.25 * sitting_like +\n",
        "             0.25 * hands_near_knees +\n",
        "             0.10 * hands_forward +\n",
        "             0.05 * symmetry)\n",
        "\n",
        "    is_tripod = (score > 0.75)\n",
        "\n",
        "    return {\n",
        "        \"tripod\": is_tripod,\n",
        "        \"score\": score,\n",
        "        \"leaning_forward\": leaning_forward,\n",
        "        \"sitting_like\": sitting_like,\n",
        "        \"hands_near_knees\": hands_near_knees,\n",
        "        \"hands_forward\": hands_forward,\n",
        "        \"symmetry\": symmetry,\n",
        "        \"torso_angle\": torso_angle,\n",
        "        \"hip_to_knee_ratio\": hip_to_knee_ratio,\n",
        "        \"dist_r\": dist_r,\n",
        "        \"dist_l\": dist_l\n",
        "    }\n",
        "\n",
        "\n",
        "def process_video_notebook(input_path, output_path=\"tripod_output.mp4\", display_every=60):\n",
        "    \"\"\"Process video frame-by-frame and optionally display progress inside notebook.\"\"\"\n",
        "    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, enable_segmentation=False)\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    if not cap.isOpened():\n",
        "        raise IOError(f\"Cannot open video: {input_path}\")\n",
        "\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 25\n",
        "    writer = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    frame_idx = 0\n",
        "    tripod_frames = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        if results.pose_landmarks:\n",
        "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "            res = evaluate_tripod_strict(results.pose_landmarks.landmark, frame.shape)\n",
        "\n",
        "            label = f\"Tripod: {'YES' if res['tripod'] else 'NO'}  score={res['score']:.2f}\"\n",
        "            color = (0, 255, 0) if res['tripod'] else (0, 0, 255)\n",
        "            cv2.rectangle(frame, (5, 5), (400, 55), (0, 0, 0), -1)\n",
        "            cv2.putText(frame, label, (10, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
        "\n",
        "            if res['tripod']:\n",
        "                tripod_frames += 1\n",
        "\n",
        "        writer.write(frame)\n",
        "\n",
        "        if frame_idx % display_every == 0:\n",
        "            print(f\"Processed frame {frame_idx}\")\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    pose.close()\n",
        "\n",
        "    tripod_ratio = tripod_frames / max(1, frame_idx)\n",
        "    print(f\"✅ Done! Tripod detected in {tripod_ratio*100:.1f}% of frames.\")\n",
        "    print(f\"Output saved to: {output_path}\")\n",
        "\n",
        "    # Display video inline in notebook\n",
        "    mp4 = open(output_path, 'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML(f'<video controls loop width=\"640\"><source src=\"{data_url}\" type=\"video/mp4\"></video>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmQ99OXOALor",
        "outputId": "156cfb75-fb30-4098-cd00-ef18459a7b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed frame 0\n",
            "Processed frame 60\n",
            "Processed frame 120\n",
            "Processed frame 180\n",
            "Processed frame 240\n",
            "Processed frame 300\n",
            "Processed frame 360\n",
            "Processed frame 420\n",
            "Processed frame 480\n",
            "Processed frame 540\n",
            "Processed frame 600\n",
            "Processed frame 660\n",
            "Processed frame 720\n",
            "Processed frame 780\n",
            "Processed frame 840\n",
            "✅ Done! Tripod detected in 0.0% of frames.\n",
            "Output saved to: tripod_detected.mp4\n"
          ]
        }
      ],
      "source": [
        "input_video = \"first_test.mp4\"\n",
        "\n",
        "# Run detection\n",
        "output = process_video_notebook(input_video, output_path=\"tripod_detected.mp4\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}